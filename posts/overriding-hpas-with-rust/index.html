<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Overriding Kubernetes HPAs with Rust |</title><meta name=keywords content><meta name=description content="Horizontal Pod Autoscalers (HPAs) are a common concept in the world of Kubernetes. They allow you to specify that your workloads should scale based on various factors, such as their CPU or memory consumption. You can also extend them with custom plugins such as the prometheus-adapter to scale based on Prometheus metrics.
However, sometimes you just want to tell Kubernetes &ldquo;give me more pods&rdquo;.
Perhaps you&rsquo;ve built up a backlog somewhere in the system, such as a processing queue."><meta name=author content><link rel=canonical href=https://alexander-jackson.github.io/posts/overriding-hpas-with-rust/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://alexander-jackson.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://alexander-jackson.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://alexander-jackson.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://alexander-jackson.github.io/apple-touch-icon.png><link rel=mask-icon href=https://alexander-jackson.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Overriding Kubernetes HPAs with Rust"><meta property="og:description" content="Horizontal Pod Autoscalers (HPAs) are a common concept in the world of Kubernetes. They allow you to specify that your workloads should scale based on various factors, such as their CPU or memory consumption. You can also extend them with custom plugins such as the prometheus-adapter to scale based on Prometheus metrics.
However, sometimes you just want to tell Kubernetes &ldquo;give me more pods&rdquo;.
Perhaps you&rsquo;ve built up a backlog somewhere in the system, such as a processing queue."><meta property="og:type" content="article"><meta property="og:url" content="https://alexander-jackson.github.io/posts/overriding-hpas-with-rust/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-09T20:01:22+01:00"><meta property="article:modified_time" content="2023-05-09T20:01:22+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Overriding Kubernetes HPAs with Rust"><meta name=twitter:description content="Horizontal Pod Autoscalers (HPAs) are a common concept in the world of Kubernetes. They allow you to specify that your workloads should scale based on various factors, such as their CPU or memory consumption. You can also extend them with custom plugins such as the prometheus-adapter to scale based on Prometheus metrics.
However, sometimes you just want to tell Kubernetes &ldquo;give me more pods&rdquo;.
Perhaps you&rsquo;ve built up a backlog somewhere in the system, such as a processing queue."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://alexander-jackson.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Overriding Kubernetes HPAs with Rust","item":"https://alexander-jackson.github.io/posts/overriding-hpas-with-rust/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Overriding Kubernetes HPAs with Rust","name":"Overriding Kubernetes HPAs with Rust","description":"Horizontal Pod Autoscalers (HPAs) are a common concept in the world of Kubernetes. They allow you to specify that your workloads should scale based on various factors, such as their CPU or memory consumption. You can also extend them with custom plugins such as the prometheus-adapter to scale based on Prometheus metrics.\nHowever, sometimes you just want to tell Kubernetes \u0026ldquo;give me more pods\u0026rdquo;.\nPerhaps you\u0026rsquo;ve built up a backlog somewhere in the system, such as a processing queue.","keywords":[],"articleBody":"Horizontal Pod Autoscalers (HPAs) are a common concept in the world of Kubernetes. They allow you to specify that your workloads should scale based on various factors, such as their CPU or memory consumption. You can also extend them with custom plugins such as the prometheus-adapter to scale based on Prometheus metrics.\nHowever, sometimes you just want to tell Kubernetes “give me more pods”.\nPerhaps you’ve built up a backlog somewhere in the system, such as a processing queue. The database looks relatively calm and the pods are chugging away, but not fast enough. The HPA likely won’t kick in, there’s not enough work being done.\nSure, you could set up metrics for this, but it’s unlikely you’ll cover every use case or reason. Sometimes you know better than the cluster.\nGeneral Approach In an ideal world, we’d just change the HPA to have more pods. This might lead to other problems though, since:\nYou may forget to revert the change, causing drift between your YAML files and actual state Kubernetes might reconcile the original values and reset them for you You may want more validation in place for these overrides One way to do this is by combining a custom resource definition (CRD) with a controller for that resource. This allows you to:\nCreate an instance of the CRD Allow the controller to validate it Merge it with the HPA using the controller This allows us to modify the state of the cluster on an adhoc basis, while having more control over what happens. We can also add custom logic, such as automatically expiring the overrides after a certain period of time.\nSetting Up Luckily for us, Rust has a library for interacting with Kubernetes that supports both generation of our own CRDs and writing controllers for resources.\nWe’ll need 3 main components here:\nA library that provides the CRD A binary that outputs the YAML definition for the cluster A binary that acts as the controller cargo supports workspaces, so we can write a top-level Cargo.toml for the workspace with our library as follows:\n[workspace] members = [ \"custom-resource\", ] Writing CRDs Let’s start out by writing the simple CRD to represent our override:\ncargo new --lib custom-resource cd custom-resource We’ll need to add a dependency on the kube crate, as well as some related libraries:\n# Kubernetes types and resources cargo add kube -F derive --no-default-features cargo add k8s-openapi -F v1_26 # Serialisation and deserialisation primitives cargo add serde -F derive cargo add serde_json # Ability to generate JSON schemas (for OpenAPI specs) cargo add schemars From here, we can define the underlying specification for our CRD and allow the kube-derive crate to generate the relevant implementation for it:\nuse std::num::NonZeroU32; use kube::CustomResource; use schemars::JsonSchema; use serde::{Deserialize, Serialize}; #[derive(Clone, Debug, CustomResource, Serialize, Deserialize, JsonSchema)] #[kube( group = \"foo.bar\", version = \"v1\", kind = \"AutoscalerOverride\", namespaced )] pub struct AutoscalerOverrideSpec { namespace: String, hpa: String, min_replicas: NonZeroU32, max_replicas: NonZeroU32, } Our resource has 4 properties, being the namespace of the HPA we’d like to override, the name of it and the new minimum and maximum values to overlay.\nThis will generate an AutoscalerOverride type that we can use elsewhere in the code. The snippet above will form the base of our CRD and we will write 2 other components, one for generating the definition to apply to the cluster and the other to control it from within the cluster.\nGenerating the Definition Now that we have a custom-resource library that defines the structure of the CRD and generates the relevant traits, we can add a small binary that depends on it and produces the YAML specification for the Kubernetes cluster. Let’s add a new member to our workspace:\n# Cargo.toml [workspace] members = [ \"custom-resource\", \"custom-resource-generator\", ] Generate our new binary:\ncargo new --bin custom-resource-generator cd custom-resource-generator Add a dependency on our CRD, as well as the kube library:\ncargo add custom-resource --path ../custom-resource cargo add kube -F derive --no-default-features From here, we can update our main function to get the resource definition, serialize it intoa YAML format and display it:\nuse custom_resource::AutoscalerOverride; use kube::core::CustomResourceExt; fn main() { let crd = AutoscalerOverride::crd(); let yaml = serde_yaml::to_string(\u0026crd).expect(\"Failed to serialize CRD\"); println!(\"{yaml}\"); } This should display something such as:\napiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: autoscaleroverrides.foo.bar spec: group: foo.bar names: categories: [] kind: AutoscalerOverride plural: autoscaleroverrides shortNames: [] singular: autoscaleroverride scope: Namespaced versions: - additionalPrinterColumns: [] name: v1 schema: openAPIV3Schema: description: Auto-generated derived type for AutoscalerOverrideSpec via `CustomResource` properties: spec: properties: hpa: type: string max_replicas: format: uint32 minimum: 1.0 type: integer min_replicas: format: uint32 minimum: 1.0 type: integer namespace: type: string required: - hpa - max_replicas - min_replicas - namespace type: object required: - spec title: AutoscalerOverride type: object served: true storage: true subresources: {} This is what we will provide to Kubernetes to allow it to understand and handle our new resource type. It mainly contains details about the schema of the type, such as that we require at least 1 for the minimum and maximum replicas due to the usage of NonZeroU32.\nWriting the Controller Now that we have a custom resource defined in Rust and YAML, we’ll need to implement a controller for it which will run inside the cluster. This will be notified of changes to our overrides and allow it to apply the relevant modifications to the horizontal pod autoscalers themselves.\nAs before, let’s add another binary to our workspace with a dependency on the custom resource crate:\n# Cargo.toml [workspace] members = [ \"custom-resource\", \"custom-resource-generator\", \"controller\", ] cargo new --bin controller cd controller cargo add custom-resource --path ../custom-resource We’ll need to make requests to the Kubernetes API server as well as listen for incoming events, so we can add an asynchronous runtime as well as the kube dependencies we’ve been using so far. Since this will run inside the cluster as a proper application, we’ll likely also want some more sophisticated logging and error handling.\n# Asynchronous runtime cargo add tokio -F \"macros rt-multi-thread\" # Kubernetes dependencies cargo add kube -F \"runtime client\" cargo add k8s-openapi -F \"v1_26\" # Logging/tracing cargo add tracing cargo add tracing-subscriber -F env-filter # Error handling cargo add color-eyre # Serializing our overrides for the API server cargo add serde -F derive # Helpers for working with streams of asynchronous data cargo add futures-util From here, we can begin defining our controller. We’ll use the Kubernetes patch method to apply our changes to the relevant horizontal pod autoscaler, so let’s define the type for that:\n#[derive(Debug, Serialize)] #[serde(rename_all = \"camelCase\")] struct HPA { min_replicas: NonZeroU32, max_replicas: NonZeroU32, } #[derive(Debug, Serialize)] struct PatchDetails { spec: HPA, } We’ll be using the Controller type from the kube crate to implement this, meaning we’ll need to define:\nA function to be run when an object we care about is modified An error handler in case the reconciliation above fails First, let’s define some types for these functions to take:\n// The type that we care about changes to type Override = Arc\u003cAutoscalerOverride\u003e; // The type of any potential errors during reconciliation type Error = kube::Error; // The context the handler gets, we don't need any type Context = Arc\u003c()\u003e; We can then define what our reconciler function should do:\n/// Receives changes to the CRD from the API server and decides how to apply them. async fn reconciler(override: Override, _ctx: Context) -\u003e Result\u003cAction, Error\u003e { let spec = override.spec.clone(); let client = Client::try_default().await?; let autoscalers: Api\u003cHorizontalPodAutoscaler\u003e = Api::namespaced(client, \u0026spec.namespace); tracing::info!(\"Got an event, parameters are {spec}\"); // Patch the HPA based on the incoming event let params = PatchParams::default(); let patch = Patch::Strategic(PatchDetails { spec: HPA { min_replicas: spec.min_replicas, max_replicas: spec.max_replicas, }, }); autoscalers.patch(\u0026spec.hpa, \u0026params, \u0026patch).await?; Ok(Action::requeue(ONE_HOUR)) } The logic for the reconciler is relatively simple, since all it needs to do is:\nGet the incoming event Connect to the API server Create a patch request Apply it to the specified resource The error handler is similarly basic:\n/// Handles errors when reconciling, simply by asking to retry a minute later. fn error_handler(object: Object, error: \u0026Error, _ctx: Context) -\u003e Action { tracing::error!(\"Got an error ({error}) on object {object:?}\"); Action::requeue(ONE_MINUTE) } Since there’s not much we can do in the case of an error at the moment (as the logic is so simple it was likely just a connection error), we just log out the error for debugging purposes and ask the API server to try again in a minute.\nNow that we have defined the reconciler and the error handler, we can create a new instance of the Controller and provide our functions to it:\n/// Entry point for the controller itself. /// /// Sets up the watching of the CRD along with the reconciler that will overlay onto the HPA. async fn run_controller() -\u003e Result\u003c()\u003e { let client = Client::try_default().await?; let overrides: Api\u003cAutoscalerOverride\u003e = Api::all(client.clone()); let autoscalers: Api\u003cHorizontalPodAutoscaler\u003e = Api::all(client.clone()); let context = Arc::new(()); let controller = Controller::new(overrides, Config::default()) .owns(autoscalers.clone(), Config::default()) .run(reconciler, error_handler, context) .for_each(|res| async move { match res { Ok(o) =\u003e tracing::info!(\"Reconciled {:?}\", o), Err(e) =\u003e tracing::error!(\"Reconcile failed: {:?}\", e), } }); tracing::info!(\"Running the controller to begin waiting for events\"); controller.await; Ok(()) } From here, we just need our main function to set up the logging for the system and start our controller:\n#[tokio::main] async fn main() { tracing_subscriber::fmt().init(); run_controller().await.expect(\"Failed to run controller\"); } Applying Overrides Now that we’ve defined our custom resource and matching controller, we can start it by running cargo run in the controller directory. We should then see our start up message (along with no errors) which indicates that it has successfully connected to the cluster and registered itself, ready to receive events.\nWe can then create a small YAML file containing the definition of the HPA we’d like to override:\n# hpa-override.yaml apiVersion: autoscaleroverrides.foo.bar/v1 kind: AutoscalerOverride spec: hpa: baz-service-hpa namespace: some-team min_replicas: 10 max_replicas: 20 Upon applying that to the cluster:\nkubernetes apply -f hpa-override.yaml we should then see the controller be informed of the change and update the baz-service-hpa in the some-team namespace (if it exists) to have a minimum of 10 replicas and a maximum of 20.\nThis allows us to quickly and easily update the number of replicas for a service without needing to change the original files.\n","wordCount":"1706","inLanguage":"en","datePublished":"2023-05-09T20:01:22+01:00","dateModified":"2023-05-09T20:01:22+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://alexander-jackson.github.io/posts/overriding-hpas-with-rust/"},"publisher":{"@type":"Organization","name":"","logo":{"@type":"ImageObject","url":"https://alexander-jackson.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Overriding Kubernetes HPAs with Rust</h1><div class=post-meta><span title='2023-05-09 20:01:22 +0100 +0100'>May 9, 2023</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#general-approach aria-label="General Approach">General Approach</a></li><li><a href=#setting-up aria-label="Setting Up">Setting Up</a><ul><li><a href=#writing-crds aria-label="Writing CRDs">Writing CRDs</a></li><li><a href=#generating-the-definition aria-label="Generating the Definition">Generating the Definition</a></li><li><a href=#writing-the-controller aria-label="Writing the Controller">Writing the Controller</a></li></ul></li><li><a href=#applying-overrides aria-label="Applying Overrides">Applying Overrides</a></li></ul></div></details></div><div class=post-content><p><a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/>Horizontal Pod Autoscalers</a> (HPAs) are a common concept in the
world of Kubernetes. They allow you to specify that your workloads should scale
based on various factors, such as their CPU or memory consumption. You can also
extend them with custom plugins such as the
<a href=https://github.com/kubernetes-sigs/prometheus-adapter>prometheus-adapter</a> to scale based on Prometheus metrics.</p><p>However, sometimes you just want to tell Kubernetes &ldquo;give me more pods&rdquo;.</p><p>Perhaps you&rsquo;ve built up a backlog somewhere in the system, such as a processing
queue. The database looks relatively calm and the pods are chugging away, but
not fast enough. The HPA likely won&rsquo;t kick in, there&rsquo;s not enough work being
done.</p><p>Sure, you could set up metrics for this, but it&rsquo;s unlikely you&rsquo;ll cover every
use case or reason. Sometimes you know better than the cluster.</p><h2 id=general-approach>General Approach<a hidden class=anchor aria-hidden=true href=#general-approach>#</a></h2><p>In an ideal world, we&rsquo;d just change the HPA to have more pods. This might lead
to other problems though, since:</p><ul><li>You may forget to revert the change, causing drift between your YAML files
and actual state</li><li>Kubernetes might reconcile the original values and reset them for you</li><li>You may want more validation in place for these overrides</li></ul><p>One way to do this is by combining a <a href=https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/>custom resource definition</a>
(CRD) with a controller for that resource. This allows you to:</p><ul><li>Create an instance of the CRD</li><li>Allow the controller to validate it</li><li>Merge it with the HPA using the controller</li></ul><p>This allows us to modify the state of the cluster on an adhoc basis, while
having more control over what happens. We can also add custom logic, such as
automatically expiring the overrides after a certain period of time.</p><h2 id=setting-up>Setting Up<a hidden class=anchor aria-hidden=true href=#setting-up>#</a></h2><p>Luckily for us, Rust has a <a href=https://docs.rs/kube>library</a> for interacting with
Kubernetes that supports both generation of our own CRDs and writing
controllers for resources.</p><p>We&rsquo;ll need 3 main components here:</p><ul><li>A library that provides the CRD</li><li>A binary that outputs the YAML definition for the cluster</li><li>A binary that acts as the controller</li></ul><p><code>cargo</code> supports workspaces, so we can write a top-level <code>Cargo.toml</code> for the
workspace with our library as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span>[<span style=color:#a6e22e>workspace</span>]
</span></span><span style=display:flex><span><span style=color:#a6e22e>members</span> = [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;custom-resource&#34;</span>,
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><h3 id=writing-crds>Writing CRDs<a hidden class=anchor aria-hidden=true href=#writing-crds>#</a></h3><p>Let&rsquo;s start out by writing the simple CRD to represent our override:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cargo new --lib custom-resource
</span></span><span style=display:flex><span>cd custom-resource
</span></span></code></pre></div><p>We&rsquo;ll need to add a dependency on the <code>kube</code> crate, as well as some related
libraries:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Kubernetes types and resources</span>
</span></span><span style=display:flex><span>cargo add kube -F derive --no-default-features
</span></span><span style=display:flex><span>cargo add k8s-openapi -F v1_26
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Serialisation and deserialisation primitives</span>
</span></span><span style=display:flex><span>cargo add serde -F derive
</span></span><span style=display:flex><span>cargo add serde_json
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Ability to generate JSON schemas (for OpenAPI specs)</span>
</span></span><span style=display:flex><span>cargo add schemars
</span></span></code></pre></div><p>From here, we can define the underlying specification for our CRD and allow the
<code>kube-derive</code> crate to generate the relevant implementation for it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>use</span> std::num::NonZeroU32;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> kube::CustomResource;
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> schemars::JsonSchema;
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> serde::{Deserialize, Serialize};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#[derive(Clone, Debug, CustomResource, Serialize, Deserialize, JsonSchema)]</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#[kube(
</span></span></span><span style=display:flex><span><span style=color:#75715e>    group = </span><span style=color:#e6db74>&#34;foo.bar&#34;</span><span style=color:#75715e>,
</span></span></span><span style=display:flex><span><span style=color:#75715e>    version = </span><span style=color:#e6db74>&#34;v1&#34;</span><span style=color:#75715e>,
</span></span></span><span style=display:flex><span><span style=color:#75715e>    kind = </span><span style=color:#e6db74>&#34;AutoscalerOverride&#34;</span><span style=color:#75715e>,
</span></span></span><span style=display:flex><span><span style=color:#75715e>    namespaced
</span></span></span><span style=display:flex><span><span style=color:#75715e>)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>AutoscalerOverrideSpec</span> {
</span></span><span style=display:flex><span>    namespace: String,
</span></span><span style=display:flex><span>    hpa: String,
</span></span><span style=display:flex><span>    min_replicas: <span style=color:#a6e22e>NonZeroU32</span>,
</span></span><span style=display:flex><span>    max_replicas: <span style=color:#a6e22e>NonZeroU32</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Our resource has 4 properties, being the namespace of the HPA we&rsquo;d like to
override, the name of it and the new minimum and maximum values to overlay.</p><p>This will generate an <code>AutoscalerOverride</code> type that we can use elsewhere in
the code. The snippet above will form the base of our CRD and we will write 2
other components, one for generating the definition to apply to the cluster and
the other to control it from within the cluster.</p><h3 id=generating-the-definition>Generating the Definition<a hidden class=anchor aria-hidden=true href=#generating-the-definition>#</a></h3><p>Now that we have a <code>custom-resource</code> library that defines the structure of the
CRD and generates the relevant traits, we can add a small binary that depends
on it and produces the YAML specification for the Kubernetes cluster. Let&rsquo;s add
a new member to our workspace:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span><span style=color:#75715e># Cargo.toml</span>
</span></span><span style=display:flex><span>[<span style=color:#a6e22e>workspace</span>]
</span></span><span style=display:flex><span><span style=color:#a6e22e>members</span> = [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;custom-resource&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;custom-resource-generator&#34;</span>,
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>Generate our new binary:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cargo new --bin custom-resource-generator
</span></span><span style=display:flex><span>cd custom-resource-generator
</span></span></code></pre></div><p>Add a dependency on our CRD, as well as the <code>kube</code> library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cargo add custom-resource --path ../custom-resource
</span></span><span style=display:flex><span>cargo add kube -F derive --no-default-features
</span></span></code></pre></div><p>From here, we can update our <code>main</code> function to get the resource definition,
serialize it intoa YAML format and display it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>use</span> custom_resource::AutoscalerOverride;
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> kube::core::CustomResourceExt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>main</span>() {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> crd <span style=color:#f92672>=</span> AutoscalerOverride::crd();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> yaml <span style=color:#f92672>=</span> serde_yaml::to_string(<span style=color:#f92672>&amp;</span>crd).expect(<span style=color:#e6db74>&#34;Failed to serialize CRD&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    println!(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{yaml}</span><span style=color:#e6db74>&#34;</span>);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This should display something such as:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>apiextensions.k8s.io/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>CustomResourceDefinition</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>autoscaleroverrides.foo.bar</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>group</span>: <span style=color:#ae81ff>foo.bar</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>names</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>categories</span>: []
</span></span><span style=display:flex><span>    <span style=color:#f92672>kind</span>: <span style=color:#ae81ff>AutoscalerOverride</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>plural</span>: <span style=color:#ae81ff>autoscaleroverrides</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>shortNames</span>: []
</span></span><span style=display:flex><span>    <span style=color:#f92672>singular</span>: <span style=color:#ae81ff>autoscaleroverride</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>scope</span>: <span style=color:#ae81ff>Namespaced</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>versions</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>additionalPrinterColumns</span>: []
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>schema</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>openAPIV3Schema</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>description</span>: <span style=color:#ae81ff>Auto-generated derived type for AutoscalerOverrideSpec via `CustomResource`</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>properties</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>properties</span>:
</span></span><span style=display:flex><span>              <span style=color:#f92672>hpa</span>:
</span></span><span style=display:flex><span>                <span style=color:#f92672>type</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>max_replicas</span>:
</span></span><span style=display:flex><span>                <span style=color:#f92672>format</span>: <span style=color:#ae81ff>uint32</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>minimum</span>: <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>type</span>: <span style=color:#ae81ff>integer</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>min_replicas</span>:
</span></span><span style=display:flex><span>                <span style=color:#f92672>format</span>: <span style=color:#ae81ff>uint32</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>minimum</span>: <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>type</span>: <span style=color:#ae81ff>integer</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>namespace</span>:
</span></span><span style=display:flex><span>                <span style=color:#f92672>type</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>required</span>:
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>hpa</span>
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>max_replicas</span>
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>min_replicas</span>
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>namespace</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>type</span>: <span style=color:#ae81ff>object</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>required</span>:
</span></span><span style=display:flex><span>        - <span style=color:#ae81ff>spec</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>title</span>: <span style=color:#ae81ff>AutoscalerOverride</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>type</span>: <span style=color:#ae81ff>object</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>served</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>storage</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>subresources</span>: {}
</span></span></code></pre></div><p>This is what we will provide to Kubernetes to allow it to understand and handle
our new resource type. It mainly contains details about the schema of the type,
such as that we require at least 1 for the minimum and maximum replicas due to
the usage of <code>NonZeroU32</code>.</p><h3 id=writing-the-controller>Writing the Controller<a hidden class=anchor aria-hidden=true href=#writing-the-controller>#</a></h3><p>Now that we have a custom resource defined in Rust and YAML, we&rsquo;ll need to
implement a controller for it which will run inside the cluster. This will be
notified of changes to our overrides and allow it to apply the relevant
modifications to the horizontal pod autoscalers themselves.</p><p>As before, let&rsquo;s add another binary to our workspace with a dependency on the
custom resource crate:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span><span style=color:#75715e># Cargo.toml</span>
</span></span><span style=display:flex><span>[<span style=color:#a6e22e>workspace</span>]
</span></span><span style=display:flex><span><span style=color:#a6e22e>members</span> = [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;custom-resource&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;custom-resource-generator&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;controller&#34;</span>,
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cargo new --bin controller
</span></span><span style=display:flex><span>cd controller
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cargo add custom-resource --path ../custom-resource
</span></span></code></pre></div><p>We&rsquo;ll need to make requests to the Kubernetes API server as well as listen for
incoming events, so we can add an asynchronous runtime as well as the <code>kube</code>
dependencies we&rsquo;ve been using so far. Since this will run inside the cluster as
a proper application, we&rsquo;ll likely also want some more sophisticated logging
and error handling.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Asynchronous runtime</span>
</span></span><span style=display:flex><span>cargo add tokio -F <span style=color:#e6db74>&#34;macros rt-multi-thread&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Kubernetes dependencies</span>
</span></span><span style=display:flex><span>cargo add kube -F <span style=color:#e6db74>&#34;runtime client&#34;</span>
</span></span><span style=display:flex><span>cargo add k8s-openapi -F <span style=color:#e6db74>&#34;v1_26&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Logging/tracing</span>
</span></span><span style=display:flex><span>cargo add tracing
</span></span><span style=display:flex><span>cargo add tracing-subscriber -F env-filter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Error handling</span>
</span></span><span style=display:flex><span>cargo add color-eyre
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Serializing our overrides for the API server</span>
</span></span><span style=display:flex><span>cargo add serde -F derive
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Helpers for working with streams of asynchronous data</span>
</span></span><span style=display:flex><span>cargo add futures-util
</span></span></code></pre></div><p>From here, we can begin defining our controller. We&rsquo;ll use the Kubernetes
<code>patch</code> method to apply our changes to the relevant horizontal pod autoscaler,
so let&rsquo;s define the type for that:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#75715e>#[derive(Debug, Serialize)]</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#[serde(rename_all = </span><span style=color:#e6db74>&#34;camelCase&#34;</span><span style=color:#75715e>)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>HPA</span> {
</span></span><span style=display:flex><span>    min_replicas: <span style=color:#a6e22e>NonZeroU32</span>,
</span></span><span style=display:flex><span>    max_replicas: <span style=color:#a6e22e>NonZeroU32</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#[derive(Debug, Serialize)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>PatchDetails</span> {
</span></span><span style=display:flex><span>    spec: <span style=color:#a6e22e>HPA</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>We&rsquo;ll be using the <a href=https://docs.rs/kube/latest/kube/runtime/struct.Controller.html><code>Controller</code></a> type from the <a href=https://docs.rs/kube><code>kube</code></a> crate to implement this, meaning we&rsquo;ll need to define:</p><ul><li>A function to be run when an object we care about is modified</li><li>An error handler in case the reconciliation above fails</li></ul><p>First, let&rsquo;s define some types for these functions to take:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#75715e>// The type that we care about changes to
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>type</span> <span style=color:#a6e22e>Override</span> <span style=color:#f92672>=</span> Arc<span style=color:#f92672>&lt;</span>AutoscalerOverride<span style=color:#f92672>&gt;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// The type of any potential errors during reconciliation
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>type</span> <span style=color:#a6e22e>Error</span> <span style=color:#f92672>=</span> kube::Error;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// The context the handler gets, we don&#39;t need any
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>type</span> <span style=color:#a6e22e>Context</span> <span style=color:#f92672>=</span> Arc<span style=color:#f92672>&lt;</span>()<span style=color:#f92672>&gt;</span>;
</span></span></code></pre></div><p>We can then define what our reconciler function should do:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#e6db74>/// Receives changes to the CRD from the API server and decides how to apply them.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>reconciler</span>(<span style=color:#66d9ef>override</span>: <span style=color:#a6e22e>Override</span>, _ctx: <span style=color:#a6e22e>Context</span>) -&gt; Result<span style=color:#f92672>&lt;</span>Action, Error<span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> spec <span style=color:#f92672>=</span> <span style=color:#66d9ef>override</span>.spec.clone();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> client <span style=color:#f92672>=</span> Client::try_default().<span style=color:#66d9ef>await</span><span style=color:#f92672>?</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> autoscalers: <span style=color:#a6e22e>Api</span><span style=color:#f92672>&lt;</span>HorizontalPodAutoscaler<span style=color:#f92672>&gt;</span> <span style=color:#f92672>=</span> Api::namespaced(client, <span style=color:#f92672>&amp;</span>spec.namespace);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    tracing::info!(<span style=color:#e6db74>&#34;Got an event, parameters are {spec}&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Patch the HPA based on the incoming event
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>let</span> params <span style=color:#f92672>=</span> PatchParams::default();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> patch <span style=color:#f92672>=</span> Patch::Strategic(PatchDetails {
</span></span><span style=display:flex><span>        spec: <span style=color:#a6e22e>HPA</span> {
</span></span><span style=display:flex><span>            min_replicas: <span style=color:#a6e22e>spec</span>.min_replicas,
</span></span><span style=display:flex><span>            max_replicas: <span style=color:#a6e22e>spec</span>.max_replicas,
</span></span><span style=display:flex><span>        },
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    autoscalers.patch(<span style=color:#f92672>&amp;</span>spec.hpa, <span style=color:#f92672>&amp;</span>params, <span style=color:#f92672>&amp;</span>patch).<span style=color:#66d9ef>await</span><span style=color:#f92672>?</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Ok(Action::requeue(<span style=color:#66d9ef>ONE_HOUR</span>))
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The logic for the reconciler is relatively simple, since all it needs to do is:</p><ul><li>Get the incoming event</li><li>Connect to the API server</li><li>Create a patch request</li><li>Apply it to the specified resource</li></ul><p>The error handler is similarly basic:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#e6db74>/// Handles errors when reconciling, simply by asking to retry a minute later.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>error_handler</span>(object: <span style=color:#a6e22e>Object</span>, error: <span style=color:#66d9ef>&amp;</span><span style=color:#a6e22e>Error</span>, _ctx: <span style=color:#a6e22e>Context</span>) -&gt; <span style=color:#a6e22e>Action</span> {
</span></span><span style=display:flex><span>    tracing::error!(<span style=color:#e6db74>&#34;Got an error ({error}) on object {object:?}&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Action::requeue(<span style=color:#66d9ef>ONE_MINUTE</span>)
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Since there&rsquo;s not much we can do in the case of an error at the moment (as the
logic is so simple it was likely just a connection error), we just log out the
error for debugging purposes and ask the API server to try again in a minute.</p><p>Now that we have defined the reconciler and the error handler, we can create a
new instance of the <a href=https://docs.rs/kube/latest/kube/runtime/struct.Controller.html><code>Controller</code></a> and provide our functions
to it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#e6db74>/// Entry point for the controller itself.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>///
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// Sets up the watching of the CRD along with the reconciler that will overlay onto the HPA.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>run_controller</span>() -&gt; Result<span style=color:#f92672>&lt;</span>()<span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> client <span style=color:#f92672>=</span> Client::try_default().<span style=color:#66d9ef>await</span><span style=color:#f92672>?</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> overrides: <span style=color:#a6e22e>Api</span><span style=color:#f92672>&lt;</span>AutoscalerOverride<span style=color:#f92672>&gt;</span> <span style=color:#f92672>=</span> Api::all(client.clone());
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> autoscalers: <span style=color:#a6e22e>Api</span><span style=color:#f92672>&lt;</span>HorizontalPodAutoscaler<span style=color:#f92672>&gt;</span> <span style=color:#f92672>=</span> Api::all(client.clone());
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> context <span style=color:#f92672>=</span> Arc::new(());
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> controller <span style=color:#f92672>=</span> Controller::new(overrides, Config::default())
</span></span><span style=display:flex><span>        .owns(autoscalers.clone(), Config::default())
</span></span><span style=display:flex><span>        .run(reconciler, error_handler, context)
</span></span><span style=display:flex><span>        .for_each(<span style=color:#f92672>|</span>res<span style=color:#f92672>|</span> <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>move</span> {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>match</span> res {
</span></span><span style=display:flex><span>                Ok(o) <span style=color:#f92672>=&gt;</span> tracing::info!(<span style=color:#e6db74>&#34;Reconciled {:?}&#34;</span>, o),
</span></span><span style=display:flex><span>                Err(e) <span style=color:#f92672>=&gt;</span> tracing::error!(<span style=color:#e6db74>&#34;Reconcile failed: {:?}&#34;</span>, e),
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    tracing::info!(<span style=color:#e6db74>&#34;Running the controller to begin waiting for events&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    controller.<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Ok(())
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>From here, we just need our <code>main</code> function to set up the logging for the
system and start our controller:</p><pre tabindex=0><code>#[tokio::main]
async fn main() {
    tracing_subscriber::fmt().init();

    run_controller().await.expect(&#34;Failed to run controller&#34;);
}
</code></pre><h2 id=applying-overrides>Applying Overrides<a hidden class=anchor aria-hidden=true href=#applying-overrides>#</a></h2><p>Now that we&rsquo;ve defined our custom resource and matching controller, we can
start it by running <code>cargo run</code> in the <code>controller</code> directory. We should then
see our start up message (along with no errors) which indicates that it has
successfully connected to the cluster and registered itself, ready to receive
events.</p><p>We can then create a small YAML file containing the definition of the HPA we&rsquo;d
like to override:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># hpa-override.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>autoscaleroverrides.foo.bar/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>AutoscalerOverride</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>hpa</span>: <span style=color:#ae81ff>baz-service-hpa</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>some-team</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>min_replicas</span>: <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>max_replicas</span>: <span style=color:#ae81ff>20</span>
</span></span></code></pre></div><p>Upon applying that to the cluster:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubernetes apply -f hpa-override.yaml
</span></span></code></pre></div><p>we should then see the controller be informed of the change and update the
<code>baz-service-hpa</code> in the <code>some-team</code> namespace (if it exists) to have a minimum
of 10 replicas and a maximum of 20.</p><p>This allows us to quickly and easily update the number of replicas for a
service without needing to change the original files.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://alexander-jackson.github.io/></a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>